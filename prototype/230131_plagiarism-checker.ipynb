{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NotIntegerError(Exception):\n",
    "    pass\n",
    "\n",
    "# 문서를 불러와 단어로 토큰화 후, 단어들을 word_list에 저장후 word_list 반환\n",
    "def doc_tokenize(doc_name):\n",
    "    with open(doc_name, 'rt') as fp:\n",
    "        string = fp.read()\n",
    "\n",
    "    word_list = word_tokenize(string)\n",
    "\n",
    "    # 유사도 계산시 정확성을 높이기 위해 큰 의미가 없는 단어인 불용어를 word_list에서 제거\n",
    "    word_list = [word for word in word_list if word not in stop_words]\n",
    "\n",
    "    # 소문자와 대문자로 인해 의미 구별이 되는 것을 방지하기 위해, 모든 단어를 소문자화\n",
    "    word_list = [word.lower() if word.islower() == False else word for word in word_list]\n",
    "\n",
    "    return word_list\n",
    "\n",
    "# list안 word의 term frequency 값 계산 후 dict 형태로 반환\n",
    "def tf(list):\n",
    "    tf_dict = {word : list.count(word) if word in list else 0 for word in word_zip}\n",
    "\n",
    "    return tf_dict\n",
    "\n",
    "# list안 word의 tf 값과 idf 값을 곱하여 tf-idf 값 계산 후 알파벳 순으로 정렬하여 list 원소가 (word, tf-idf) 형식을 가진 list 형태로 반환\n",
    "def tf_idf(list):\n",
    "    tf_dict = tf(list)\n",
    "    tf_idf_dict = {word : tf_dict[word] * idf_dict[word] for word in tf_dict.keys()}\n",
    "\n",
    "    return sorted(tf_idf_dict.items())\n",
    "\n",
    "# doc_1과 doc_2 문서의 cosine 유사도를 계산 후 유사도 값을 반환\n",
    "def cos_similarity(doc_1_name, doc_2_name):\n",
    "    # doc_1과 doc_2 문서의 tf-idf값 계산\n",
    "    doc_1 = tf_idf(doc_tokenize(doc_1_name))\n",
    "    doc_2 = tf_idf(doc_tokenize(doc_2_name))\n",
    "\n",
    "    # doc_1의 word의 tf-idf 값을 vactor_1에 할당\n",
    "    vector_1 = [value[1] for value in doc_1]\n",
    "\n",
    "    # doc_2의 word의 tf-idf 값을 vactor_2에 할당\n",
    "    vector_2 = [value[1] for value in doc_2]\n",
    "\n",
    "    # vector_1과 vector_2 사이의 각도를 구한후 100을 곱하여 % 수치로 반환, 소숫점 2자리까지 반올림\n",
    "    return round((dot(vector_1, vector_2) / (norm(vector_1) * norm(vector_2)))*100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n",
      "Please enter the name of an existing document.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    try:\n",
    "        # 문서 수 입력\n",
    "        doc_count = float(input('Please enter the count of documents : '))\n",
    "\n",
    "        if doc_count % 1 != 0:\n",
    "            raise NotIntegerError()\n",
    "\n",
    "        doc_count = int(doc_count)\n",
    "        doc_name_list = []\n",
    "\n",
    "        i = 0\n",
    "        while i < doc_count:\n",
    "            doc_name = input(f'Please enter the name of documents [{i + 1}{\"/\"}{doc_count}] : ') + \".txt\"\n",
    "\n",
    "            # 존재하지 않은 문서 이름을 입력시 다시 입력, 존재하는 문서 입력시 doc_name_list에 할당\n",
    "            if os.path.isfile(doc_name):\n",
    "                doc_name_list.append(doc_name)\n",
    "                i += 1\n",
    "            else:\n",
    "                print('Please enter the name of an existing document.')\n",
    "        break\n",
    "    except ValueError:\n",
    "        # 문서 수를 입력할 때 숫자를 입력하지 않으면 excpet 발생\n",
    "        print('Please enter the number.')\n",
    "    except NotIntegerError:\n",
    "        # 문서 수를 입력할 때 정수를 입력하지 않으면 excpet 발생\n",
    "        print('Please enter the integer.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# idf 값을 계산하기 위해 모든 문서를 doc_zip에 할당\n",
    "doc_zip = [doc_tokenize(name) for name in doc_name_list]\n",
    "\n",
    "# tf-idf 값을 계산하기 위해 모든 문서의 단어를 중복되지 않게 word_zip에 할당\n",
    "word_zip = list(set([word for doc in doc_zip for word in doc]))\n",
    "\n",
    "# 각 단어마다 inverse document frequency 값 계산 후 dict에 할당\n",
    "idf_dict = {}\n",
    "for word in word_zip:\n",
    "    word_count = 0\n",
    "    for doc in doc_zip:\n",
    "        if word in doc:\n",
    "            word_count += 1\n",
    "    idf_dict[word] = np.log((1 + doc_count) / (word_count))\n",
    "\n",
    "# 경로 상의 모든 문서의 서로 간의 유사도를 계산 후 similarity_dict에 저장\n",
    "similarity_dict = {(doc_name_list[i], doc_name_list[j]) : cos_similarity(doc_name_list[i], doc_name_list[j]) for i in range(len(doc_name_list)-1) for j in range(i+1, doc_count)}\n",
    "\n",
    "# 유사도가 가장 큰 문서 2개를 계산 후 출력\n",
    "key_min = max(similarity_dict.keys(), key = lambda x: similarity_dict[x])\n",
    "value_min = max(similarity_dict.values())\n",
    "\n",
    "print(f\"The similarity between {key_min[0]} and {key_min[1]} is highest at {value_min}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
